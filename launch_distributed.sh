#!/bin/bash
# Launch script for distributed training on 8x RTX 4090 GPUs

echo "üöÄ Launching Distributed Training on 8x RTX 4090 GPUs"
echo "üìä Total batch size: 1536 (192 per GPU)"
echo "‚ö° Using PyTorch DistributedDataParallel (DDP)"

# Check if GPUs are available
if ! command -v nvidia-smi &> /dev/null; then
    echo "‚ùå nvidia-smi not found. Please ensure NVIDIA drivers are installed."
    exit 1
fi

echo "üîç Available GPUs:"
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits

# Check GPU count
GPU_COUNT=$(nvidia-smi --query-gpu=name --format=csv,noheader | wc -l)
echo "üìä Detected $GPU_COUNT GPUs"

if [ "$GPU_COUNT" -lt 8 ]; then
    echo "‚ö†Ô∏è  Warning: Only $GPU_COUNT GPUs detected, but script is configured for 8 GPUs"
    echo "You can modify the --nproc_per_node parameter in this script"
fi

# Set environment variables for optimal performance
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export NCCL_DEBUG=INFO
export NCCL_TREE_THRESHOLD=0

# Launch distributed training with torchrun (recommended for PyTorch 1.10+)
echo "üöÄ Starting distributed training..."
torchrun \
    --nproc_per_node=8 \
    --master_port=29500 \
    train_distributed.py

echo "‚úÖ Training launch completed!"
